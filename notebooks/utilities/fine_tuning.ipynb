{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (1.3.7)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from openai) (0.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from openai) (2.5.2)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from anyio<4,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from anyio<4,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.5)\n",
      "Requirement already satisfied: python-dotenv in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "\n",
      "- Your file contains 656 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- There are 1 duplicated prompt-completion sets. These are rows: [262]\n",
      "- All prompts end with suffix `\\n\\nRelevant:`. This suffix seems very long. Consider replacing with a shorter suffix, such as `\\n\\n###\\n\\n`\n",
      "- All prompts start with prefix `Process: `\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Remove 1 duplicate rows [Y/n]: Y\n",
      "- [Recommended] Would you like to split into training and validation set? [Y/n]: Y\n",
      "\n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
      "\n",
      "Wrote modified files to `../data/processed/train_davinci_classification_prepared_train.jsonl` and `../data/processed/train_davinci_classification_prepared_valid.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"../data/processed/train_davinci_classification_prepared_train.jsonl\" -v \"../data/processed/train_davinci_classification_prepared_valid.jsonl\" --compute_classification_metrics --classification_positive_class \" 0###\"\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\n\\nRelevant:` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"###\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 18.05 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "!openai tools fine_tunes.prepare_data -f ../data/processed/train_davinci_classification.jsonl -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: openai api [-h]\n",
      "                  {chat.completions.create,images.generate,images.edit,images.create_variation,audio.transcriptions.create,audio.translations.create,files.create,files.retrieve,files.delete,files.list,models.list,models.retrieve,models.delete,completions.create}\n",
      "                  ...\n",
      "openai api: error: argument {chat.completions.create,images.generate,images.edit,images.create_variation,audio.transcriptions.create,audio.translations.create,files.create,files.retrieve,files.delete,files.list,models.list,models.retrieve,models.delete,completions.create}: invalid choice: 'fine_tunes.create' (choose from 'chat.completions.create', 'images.generate', 'images.edit', 'images.create_variation', 'audio.transcriptions.create', 'audio.translations.create', 'files.create', 'files.retrieve', 'files.delete', 'files.list', 'models.list', 'models.retrieve', 'models.delete', 'completions.create')\n"
     ]
    }
   ],
   "source": [
    "## As 1 is relevant and 0 is not relevant, I marked it as a positve class \n",
    "!openai api fine_tunes.create -m \"davinci-002\" -t \"../data/processed/train_davinci_classification_prepared_train.jsonl\" -v \"../data/processed/train_davinci_classification_prepared_valid.jsonl\" --compute_classification_metrics --classification_positive_class \" 1###\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Multipart file uploads must be opened in binary mode, not text mode.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/patrickahrend/Developer/TUM-NLP-Praktikum/notebooks/fine_tuning.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/patrickahrend/Developer/TUM-NLP-Praktikum/notebooks/fine_tuning.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m training_file \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mfiles\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/patrickahrend/Developer/TUM-NLP-Praktikum/notebooks/fine_tuning.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m   file\u001b[39m=\u001b[39;49m\u001b[39mopen\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39m../data/processed/train_davinci_classification_prepared_train.jsonl\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/patrickahrend/Developer/TUM-NLP-Praktikum/notebooks/fine_tuning.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m   purpose\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mfine-tune\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/patrickahrend/Developer/TUM-NLP-Praktikum/notebooks/fine_tuning.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/patrickahrend/Developer/TUM-NLP-Praktikum/notebooks/fine_tuning.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m validation_file \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mfiles\u001b[39m.\u001b[39mcreate(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/patrickahrend/Developer/TUM-NLP-Praktikum/notebooks/fine_tuning.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   file\u001b[39m=\u001b[39m\u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m../data/processed/train_davinci_classification_prepared_valid.jsonl\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/patrickahrend/Developer/TUM-NLP-Praktikum/notebooks/fine_tuning.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m   purpose\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfine-tune\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/patrickahrend/Developer/TUM-NLP-Praktikum/notebooks/fine_tuning.ipynb#X24sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages/openai/resources/files.py:95\u001b[0m, in \u001b[0;36mFiles.create\u001b[0;34m(self, file, purpose, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mif\u001b[39;00m files:\n\u001b[1;32m     90\u001b[0m     \u001b[39m# It should be noted that the actual Content-Type header that will be\u001b[39;00m\n\u001b[1;32m     91\u001b[0m     \u001b[39m# sent to the server will contain a `boundary` parameter, e.g.\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     \u001b[39m# multipart/form-data; boundary=---abc--\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     extra_headers \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mContent-Type\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mmultipart/form-data\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(extra_headers \u001b[39mor\u001b[39;00m {})}\n\u001b[0;32m---> 95\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[1;32m     96\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39m/files\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     97\u001b[0m     body\u001b[39m=\u001b[39;49mmaybe_transform(body, file_create_params\u001b[39m.\u001b[39;49mFileCreateParams),\n\u001b[1;32m     98\u001b[0m     files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m     99\u001b[0m     options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[1;32m    100\u001b[0m         extra_headers\u001b[39m=\u001b[39;49mextra_headers, extra_query\u001b[39m=\u001b[39;49mextra_query, extra_body\u001b[39m=\u001b[39;49mextra_body, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    101\u001b[0m     ),\n\u001b[1;32m    102\u001b[0m     cast_to\u001b[39m=\u001b[39;49mFileObject,\n\u001b[1;32m    103\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages/openai/_base_client.py:1096\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1082\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[1;32m   1083\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1084\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1091\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1092\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m   1093\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[1;32m   1094\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[1;32m   1095\u001b[0m     )\n\u001b[0;32m-> 1096\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages/openai/_base_client.py:856\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    848\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    849\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    854\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    855\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m--> 856\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m    857\u001b[0m         cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[1;32m    858\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m    859\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    860\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m    861\u001b[0m         remaining_retries\u001b[39m=\u001b[39;49mremaining_retries,\n\u001b[1;32m    862\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages/openai/_base_client.py:876\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_options(options)\n\u001b[1;32m    875\u001b[0m retries \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_remaining_retries(remaining_retries, options)\n\u001b[0;32m--> 876\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_request(options)\n\u001b[1;32m    877\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_request(request)\n\u001b[1;32m    879\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages/openai/_base_client.py:469\u001b[0m, in \u001b[0;36mBaseClient._build_request\u001b[0;34m(self, options)\u001b[0m\n\u001b[1;32m    466\u001b[0m         kwargs[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_serialize_multipartform(json_data)\n\u001b[1;32m    468\u001b[0m \u001b[39m# TODO: report this error to httpx\u001b[39;00m\n\u001b[0;32m--> 469\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49mbuild_request(  \u001b[39m# pyright: ignore[reportUnknownMemberType]\u001b[39;49;00m\n\u001b[1;32m    470\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    471\u001b[0m     timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(options\u001b[39m.\u001b[39;49mtimeout, NotGiven) \u001b[39melse\u001b[39;49;00m options\u001b[39m.\u001b[39;49mtimeout,\n\u001b[1;32m    472\u001b[0m     method\u001b[39m=\u001b[39;49moptions\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    473\u001b[0m     url\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_url(options\u001b[39m.\u001b[39;49murl),\n\u001b[1;32m    474\u001b[0m     \u001b[39m# the `Query` type that we use is incompatible with qs'\u001b[39;49;00m\n\u001b[1;32m    475\u001b[0m     \u001b[39m# `Params` type as it needs to be typed as `Mapping[str, object]`\u001b[39;49;00m\n\u001b[1;32m    476\u001b[0m     \u001b[39m# so that passing a `TypedDict` doesn't cause an error.\u001b[39;49;00m\n\u001b[1;32m    477\u001b[0m     \u001b[39m# https://github.com/microsoft/pyright/issues/3526#event-6715453066\u001b[39;49;00m\n\u001b[1;32m    478\u001b[0m     params\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mqs\u001b[39m.\u001b[39;49mstringify(cast(Mapping[\u001b[39mstr\u001b[39;49m, Any], params)) \u001b[39mif\u001b[39;49;00m params \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    479\u001b[0m     json\u001b[39m=\u001b[39;49mjson_data,\n\u001b[1;32m    480\u001b[0m     files\u001b[39m=\u001b[39;49moptions\u001b[39m.\u001b[39;49mfiles,\n\u001b[1;32m    481\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    482\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages/httpx/_client.py:358\u001b[0m, in \u001b[0;36mBaseClient.build_request\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, timeout, extensions)\u001b[0m\n\u001b[1;32m    352\u001b[0m     timeout \u001b[39m=\u001b[39m (\n\u001b[1;32m    353\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout\n\u001b[1;32m    354\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(timeout, UseClientDefault)\n\u001b[1;32m    355\u001b[0m         \u001b[39melse\u001b[39;00m Timeout(timeout)\n\u001b[1;32m    356\u001b[0m     )\n\u001b[1;32m    357\u001b[0m     extensions \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mextensions, timeout\u001b[39m=\u001b[39mtimeout\u001b[39m.\u001b[39mas_dict())\n\u001b[0;32m--> 358\u001b[0m \u001b[39mreturn\u001b[39;00m Request(\n\u001b[1;32m    359\u001b[0m     method,\n\u001b[1;32m    360\u001b[0m     url,\n\u001b[1;32m    361\u001b[0m     content\u001b[39m=\u001b[39;49mcontent,\n\u001b[1;32m    362\u001b[0m     data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    363\u001b[0m     files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    364\u001b[0m     json\u001b[39m=\u001b[39;49mjson,\n\u001b[1;32m    365\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    366\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    367\u001b[0m     cookies\u001b[39m=\u001b[39;49mcookies,\n\u001b[1;32m    368\u001b[0m     extensions\u001b[39m=\u001b[39;49mextensions,\n\u001b[1;32m    369\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages/httpx/_models.py:338\u001b[0m, in \u001b[0;36mRequest.__init__\u001b[0;34m(self, method, url, params, headers, cookies, content, data, files, json, stream, extensions)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[39mif\u001b[39;00m stream \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    337\u001b[0m     content_type: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcontent-type\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 338\u001b[0m     headers, stream \u001b[39m=\u001b[39m encode_request(\n\u001b[1;32m    339\u001b[0m         content\u001b[39m=\u001b[39;49mcontent,\n\u001b[1;32m    340\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    341\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    342\u001b[0m         json\u001b[39m=\u001b[39;49mjson,\n\u001b[1;32m    343\u001b[0m         boundary\u001b[39m=\u001b[39;49mget_multipart_boundary_from_content_type(\n\u001b[1;32m    344\u001b[0m             content_type\u001b[39m=\u001b[39;49mcontent_type\u001b[39m.\u001b[39;49mencode(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mheaders\u001b[39m.\u001b[39;49mencoding)\n\u001b[1;32m    345\u001b[0m             \u001b[39mif\u001b[39;49;00m content_type\n\u001b[1;32m    346\u001b[0m             \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m    347\u001b[0m         ),\n\u001b[1;32m    348\u001b[0m     )\n\u001b[1;32m    349\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare(headers)\n\u001b[1;32m    350\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream \u001b[39m=\u001b[39m stream\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages/httpx/_content.py:210\u001b[0m, in \u001b[0;36mencode_request\u001b[0;34m(content, data, files, json, boundary)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[39mreturn\u001b[39;00m encode_content(content)\n\u001b[1;32m    209\u001b[0m \u001b[39melif\u001b[39;00m files:\n\u001b[0;32m--> 210\u001b[0m     \u001b[39mreturn\u001b[39;00m encode_multipart_data(data \u001b[39mor\u001b[39;49;00m {}, files, boundary)\n\u001b[1;32m    211\u001b[0m \u001b[39melif\u001b[39;00m data:\n\u001b[1;32m    212\u001b[0m     \u001b[39mreturn\u001b[39;00m encode_urlencoded_data(data)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages/httpx/_content.py:155\u001b[0m, in \u001b[0;36mencode_multipart_data\u001b[0;34m(data, files, boundary)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode_multipart_data\u001b[39m(\n\u001b[1;32m    153\u001b[0m     data: RequestData, files: RequestFiles, boundary: Optional[\u001b[39mbytes\u001b[39m]\n\u001b[1;32m    154\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m], MultipartStream]:\n\u001b[0;32m--> 155\u001b[0m     multipart \u001b[39m=\u001b[39m MultipartStream(data\u001b[39m=\u001b[39;49mdata, files\u001b[39m=\u001b[39;49mfiles, boundary\u001b[39m=\u001b[39;49mboundary)\n\u001b[1;32m    156\u001b[0m     headers \u001b[39m=\u001b[39m multipart\u001b[39m.\u001b[39mget_headers()\n\u001b[1;32m    157\u001b[0m     \u001b[39mreturn\u001b[39;00m headers, multipart\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages/httpx/_multipart.py:208\u001b[0m, in \u001b[0;36mMultipartStream.__init__\u001b[0;34m(self, data, files, boundary)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mboundary \u001b[39m=\u001b[39m boundary\n\u001b[1;32m    205\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontent_type \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmultipart/form-data; boundary=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m boundary\u001b[39m.\u001b[39mdecode(\n\u001b[1;32m    206\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mascii\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    207\u001b[0m )\n\u001b[0;32m--> 208\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfields \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iter_fields(data, files))\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages/httpx/_multipart.py:222\u001b[0m, in \u001b[0;36mMultipartStream._iter_fields\u001b[0;34m(self, data, files)\u001b[0m\n\u001b[1;32m    220\u001b[0m file_items \u001b[39m=\u001b[39m files\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(files, typing\u001b[39m.\u001b[39mMapping) \u001b[39melse\u001b[39;00m files\n\u001b[1;32m    221\u001b[0m \u001b[39mfor\u001b[39;00m name, value \u001b[39min\u001b[39;00m file_items:\n\u001b[0;32m--> 222\u001b[0m     \u001b[39myield\u001b[39;00m FileField(name\u001b[39m=\u001b[39;49mname, value\u001b[39m=\u001b[39;49mvalue)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages/httpx/_multipart.py:129\u001b[0m, in \u001b[0;36mFileField.__init__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    126\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMultipart file uploads require \u001b[39m\u001b[39m'\u001b[39m\u001b[39mio.BytesIO\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, not \u001b[39m\u001b[39m'\u001b[39m\u001b[39mio.StringIO\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    127\u001b[0m     )\n\u001b[1;32m    128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fileobj, io\u001b[39m.\u001b[39mTextIOBase):\n\u001b[0;32m--> 129\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    130\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMultipart file uploads must be opened in binary mode, not text mode.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m     )\n\u001b[1;32m    133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilename \u001b[39m=\u001b[39m filename\n\u001b[1;32m    134\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile \u001b[39m=\u001b[39m fileobj\n",
      "\u001b[0;31mTypeError\u001b[0m: Multipart file uploads must be opened in binary mode, not text mode."
     ]
    }
   ],
   "source": [
    "training_file = client.files.create(\n",
    "  file=open(\"../data/processed/train_davinci_classification_prepared_train.jsonl\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "validation_file = client.files.create(\n",
    "  file=open(\"../data/processed/train_davinci_classification_prepared_valid.jsonl\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "create() got an unexpected keyword argument 'compute_classification_metrics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/patrickahrend/Developer/TUM-NLP-Praktikum/notebooks/fine_tuning.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/patrickahrend/Developer/TUM-NLP-Praktikum/notebooks/fine_tuning.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m fine_tune \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mfine_tuning\u001b[39m.\u001b[39;49mjobs\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/patrickahrend/Developer/TUM-NLP-Praktikum/notebooks/fine_tuning.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m   training_file\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mfile-tGHmHWUw783C2XVxGCyDx2qi\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/patrickahrend/Developer/TUM-NLP-Praktikum/notebooks/fine_tuning.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m   validation_file\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mfile-PjRUGGKP5DvVsd9g4SPhYgqg\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/patrickahrend/Developer/TUM-NLP-Praktikum/notebooks/fine_tuning.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m   model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdavinci-002\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/patrickahrend/Developer/TUM-NLP-Praktikum/notebooks/fine_tuning.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m   compute_classification_metrics\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/patrickahrend/Developer/TUM-NLP-Praktikum/notebooks/fine_tuning.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m   classification_positive_class\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/patrickahrend/Developer/TUM-NLP-Praktikum/notebooks/fine_tuning.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: create() got an unexpected keyword argument 'compute_classification_metrics'"
     ]
    }
   ],
   "source": [
    "fine_tune = client.fine_tuning.jobs.create(\n",
    "  training_file=\"file-tGHmHWUw783C2XVxGCyDx2qi\",\n",
    "  validation_file=\"file-PjRUGGKP5DvVsd9g4SPhYgqg\",\n",
    "  model=\"davinci-002\",\n",
    "  compute_classification_metrics=True,\n",
    "  classification_positive_class=\"1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"text-search-babbage-doc-001\",\n",
      "  \"created\": 1651172509,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-dev\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"curie-search-query\",\n",
      "  \"created\": 1651172509,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-dev\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"text-davinci-003\",\n",
      "  \"created\": 1669599635,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-internal\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"gpt-3.5-turbo-1106\",\n",
      "  \"created\": 1698959748,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"system\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"text-search-babbage-query-001\",\n",
      "  \"created\": 1651172509,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-dev\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"babbage\",\n",
      "  \"created\": 1649358449,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"babbage-search-query\",\n",
      "  \"created\": 1651172509,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-dev\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"text-babbage-001\",\n",
      "  \"created\": 1649364043,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"text-similarity-davinci-001\",\n",
      "  \"created\": 1651172505,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-dev\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"davinci-similarity\",\n",
      "  \"created\": 1651172509,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-dev\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"code-davinci-edit-001\",\n",
      "  \"created\": 1649880484,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"curie-similarity\",\n",
      "  \"created\": 1651172510,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-dev\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"babbage-search-document\",\n",
      "  \"created\": 1651172510,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-dev\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"curie-instruct-beta\",\n",
      "  \"created\": 1649364042,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"text-search-ada-doc-001\",\n",
      "  \"created\": 1651172507,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-dev\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"davinci-instruct-beta\",\n",
      "  \"created\": 1649364042,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"text-similarity-babbage-001\",\n",
      "  \"created\": 1651172505,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-dev\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"text-search-davinci-doc-001\",\n",
      "  \"created\": 1651172505,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-dev\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"babbage-similarity\",\n",
      "  \"created\": 1651172505,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-dev\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"text-embedding-ada-002\",\n",
      "  \"created\": 1671217299,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-internal\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"davinci-search-query\",\n",
      "  \"created\": 1651172505,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-dev\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"text-similarity-curie-001\",\n",
      "  \"created\": 1651172507,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-dev\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"text-davinci-001\",\n",
      "  \"created\": 1649364042,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"text-search-davinci-query-001\",\n",
      "  \"created\": 1651172505,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-dev\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"gpt-3.5-turbo-16k-0613\",\n",
      "  \"created\": 1685474247,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"ada-search-document\",\n",
      "  \"created\": 1651172507,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-dev\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"ada-code-search-code\",\n",
      "  \"created\": 1651172505,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-dev\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"babbage-002\",\n",
      "  \"created\": 1692634615,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"system\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"gpt-4-1106-preview\",\n",
      "  \"created\": 1698957206,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"system\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"davinci-002\",\n",
      "  \"created\": 1692634301,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"system\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"davinci-search-document\",\n",
      "  \"created\": 1651172509,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-dev\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"curie-search-document\",\n",
      "  \"created\": 1651172508,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-dev\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"babbage-code-search-code\",\n",
      "  \"created\": 1651172509,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-dev\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"text-search-ada-query-001\",\n",
      "  \"created\": 1651172505,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-dev\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"code-search-ada-text-001\",\n",
      "  \"created\": 1651172507,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-dev\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"babbage-code-search-text\",\n",
      "  \"created\": 1651172509,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-dev\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"code-search-babbage-code-001\",\n",
      "  \"created\": 1651172507,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-dev\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"ada-search-query\",\n",
      "  \"created\": 1651172505,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-dev\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"ada-code-search-text\",\n",
      "  \"created\": 1651172510,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-dev\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"tts-1-hd\",\n",
      "  \"created\": 1699046015,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"system\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"text-search-curie-query-001\",\n",
      "  \"created\": 1651172509,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-dev\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"gpt-3.5-turbo\",\n",
      "  \"created\": 1677610602,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"gpt-3.5-turbo-0613\",\n",
      "  \"created\": 1686587434,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"text-davinci-002\",\n",
      "  \"created\": 1649880484,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"text-davinci-edit-001\",\n",
      "  \"created\": 1649809179,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"code-search-babbage-text-001\",\n",
      "  \"created\": 1651172507,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-dev\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"ada\",\n",
      "  \"created\": 1649357491,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"text-ada-001\",\n",
      "  \"created\": 1649364042,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"ada-similarity\",\n",
      "  \"created\": 1651172507,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-dev\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"code-search-ada-code-001\",\n",
      "  \"created\": 1651172507,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-dev\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"gpt-3.5-turbo-instruct\",\n",
      "  \"created\": 1692901427,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"system\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"text-similarity-ada-001\",\n",
      "  \"created\": 1651172505,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-dev\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"gpt-3.5-turbo-instruct-0914\",\n",
      "  \"created\": 1694122472,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"system\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"text-search-curie-doc-001\",\n",
      "  \"created\": 1651172509,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-dev\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"gpt-3.5-turbo-16k\",\n",
      "  \"created\": 1683758102,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-internal\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"gpt-4-vision-preview\",\n",
      "  \"created\": 1698894917,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"system\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"text-curie-001\",\n",
      "  \"created\": 1649364043,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"curie\",\n",
      "  \"created\": 1649359874,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"gpt-4\",\n",
      "  \"created\": 1687882411,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"tts-1\",\n",
      "  \"created\": 1681940951,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-internal\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"whisper-1\",\n",
      "  \"created\": 1677532384,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai-internal\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"gpt-4-0314\",\n",
      "  \"created\": 1687882410,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"davinci\",\n",
      "  \"created\": 1649359874,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"dall-e-2\",\n",
      "  \"created\": 1698798177,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"system\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"tts-1-1106\",\n",
      "  \"created\": 1699053241,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"system\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"gpt-3.5-turbo-0301\",\n",
      "  \"created\": 1677649963,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"tts-1-hd-1106\",\n",
      "  \"created\": 1699053533,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"system\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"dall-e-3\",\n",
      "  \"created\": 1698785189,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"system\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"gpt-4-0613\",\n",
      "  \"created\": 1686588896,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"davinci:ft-personal-2023-01-14-20-14-01\",\n",
      "  \"created\": 1673727241,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"user-fy6f3uyvepwwor2fr87xdt8c\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"davinci:ft-personal-2023-01-15-10-57-53\",\n",
      "  \"created\": 1673780273,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"user-fy6f3uyvepwwor2fr87xdt8c\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"ft:davinci-002:personal::8QMI10LR\",\n",
      "  \"created\": 1701292901,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"user-fy6f3uyvepwwor2fr87xdt8c\"\n",
      "}\n",
      "{\n",
      "  \"id\": \"ft:gpt-3.5-turbo-1106:personal::8QjJo8O4\",\n",
      "  \"created\": 1701381424,\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"user-fy6f3uyvepwwor2fr87xdt8c\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!openai api models.list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tum-nlp-praktikum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
