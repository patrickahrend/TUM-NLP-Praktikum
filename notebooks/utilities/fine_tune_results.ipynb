{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (1.3.6)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from openai) (0.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from openai) (2.5.2)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from anyio<4,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from anyio<4,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.5)\n",
      "Requirement already satisfied: python-dotenv in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (1.0.0)\n",
      "Requirement already satisfied: openai in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (1.3.6)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from openai) (0.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from openai) (2.5.2)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from anyio<4,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from anyio<4,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.5)\n",
      "Collecting requests\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.3.2-cp39-cp39-macosx_10_9_x86_64.whl.metadata (33 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from requests) (3.6)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/envs/tum-nlp-praktikum/lib/python3.9/site-packages (from requests) (2023.11.17)\n",
      "Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.3.2-cp39-cp39-macosx_10_9_x86_64.whl (122 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.5/122.5 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.6/104.6 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: urllib3, charset-normalizer, requests\n",
      "Successfully installed charset-normalizer-3.3.2 requests-2.31.0 urllib3-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!pip install python-dotenv\n",
    "!pip install --upgrade openai\n",
    "!pip install requests\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching the results of the fine-tuning job from OpenAI \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = client.files.list()\n",
    "fine_tune_results_files = [job for job in file_list.data if job.purpose == 'fine-tune-results']\n",
    "\n",
    "\n",
    "sorted_files = sorted(fine_tune_results_files, key=lambda x: x.created_at)\n",
    "\n",
    "\n",
    "if sorted_files:\n",
    "    davinci_fine_tuning_id = sorted_files[0].id \n",
    "    if len(sorted_files) > 1:\n",
    "        gpt_fine_tuning_id = sorted_files[1].id  #\n",
    "    else:\n",
    "        gpt_fine_tuning_id = \"\" \n",
    "else:\n",
    "    davinci_fine_tuning_id = \"\"\n",
    "    gpt_fine_tuning_id = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-5G5srK2jzDUlnGPrUASV8Lwd\n"
     ]
    }
   ],
   "source": [
    "print(gpt_fine_tuning_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-LhvHYcvlEfp2yWM4vxs4DxHZ\n"
     ]
    }
   ],
   "source": [
    "print(davinci_fine_tuning_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p8/j40fdn353n30l2nvsd_70qgc0000gn/T/ipykernel_37365/2065847974.py:1: DeprecationWarning: The `.content()` method should be used instead\n",
      "  gpt_file = client.files.retrieve_content(gpt_fine_tuning_id)\n",
      "/var/folders/p8/j40fdn353n30l2nvsd_70qgc0000gn/T/ipykernel_37365/2065847974.py:2: DeprecationWarning: The `.content()` method should be used instead\n",
      "  davinci_file= client.files.retrieve_content(davinci_fine_tuning_id)\n"
     ]
    }
   ],
   "source": [
    "gpt_file = client.files.retrieve_content(gpt_fine_tuning_id)\n",
    "davinci_file= client.files.retrieve_content(davinci_fine_tuning_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"../data/interim/gpt_fine_tuning_results.csv\", \"w\", encoding='utf-8') as file:\n",
    "    file.write(gpt_file)\n",
    "\n",
    "with open(\"../data/interim/davinci_fine_tuning_results.csv\", \"w\", encoding='utf-8') as file:\n",
    "    file.write(davinci_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_mean_token_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>1968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      step  train_loss  train_accuracy  valid_loss  valid_mean_token_accuracy\n",
       "1967  1968         0.0         0.33333         NaN                        NaN"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results_gpt = pd.read_csv('../data/interim/gpt_fine_tuning_results.csv')\n",
    "results_gpt[results_gpt['train_accuracy'].notnull()].tail(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tum-nlp-praktikum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
